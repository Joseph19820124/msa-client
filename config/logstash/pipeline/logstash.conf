# Logstash Configuration for Microservices Log Processing

input {
  # Beats input for collecting logs from all services
  beats {
    port => 5044
  }

  # Direct file input for nginx logs
  file {
    path => "/var/log/nginx/*.log"
    start_position => "beginning"
    tags => ["nginx"]
  }

  # Syslog input for system logs
  syslog {
    port => 514
    tags => ["syslog"]
  }

  # Docker logs input
  file {
    path => "/var/lib/docker/containers/*/*.log"
    start_position => "beginning"
    tags => ["docker"]
    codec => json
  }
}

filter {
  # Parse timestamp
  date {
    match => [ "timestamp", "ISO8601" ]
    target => "@timestamp"
  }

  # Service-specific processing
  if [fields][service] {
    mutate {
      add_field => { "service_name" => "%{[fields][service]}" }
    }
  }

  # Process API Gateway logs
  if [service_name] == "api-gateway" {
    if [message] =~ /^{.*}$/ {
      json {
        source => "message"
      }
      
      # Extract request details
      if [req] {
        mutate {
          add_field => { 
            "http_method" => "%{[req][method]}"
            "http_url" => "%{[req][url]}"
            "user_agent" => "%{[req][headers][user-agent]}"
            "remote_ip" => "%{[req][ip]}"
          }
        }
      }
      
      # Extract response details
      if [res] {
        mutate {
          add_field => { 
            "http_status" => "%{[res][statusCode]}"
            "response_time" => "%{[responseTime]}"
          }
        }
      }
    }
  }

  # Process Auth Service logs
  if [service_name] == "auth-service" {
    grok {
      match => { 
        "message" => "(?<log_timestamp>\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}.\d{3}Z) \[%{WORD:log_level}\] %{GREEDYDATA:log_message}"
      }
    }

    # Parse authentication events
    if [log_message] =~ /login/ {
      grok {
        match => { 
          "log_message" => "(?i)login %{WORD:auth_result} for user (?<user_email>\S+@\S+\.\S+) from IP (?<source_ip>\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b)"
        }
      }
      
      mutate {
        add_tag => ["authentication"]
      }
    }

    # Parse registration events
    if [log_message] =~ /registration/ {
      grok {
        match => { 
          "log_message" => "(?i)user registration (?<registration_result>\w+) for (?<user_email>\S+@\S+\.\S+)"
        }
      }
      
      mutate {
        add_tag => ["registration"]
      }
    }
  }

  # Process Posts Service logs
  if [service_name] == "posts-service" {
    if [message] =~ /^{.*}$/ {
      json {
        source => "message"
      }
      
      # Extract post creation events
      if [action] == "post_created" {
        mutate {
          add_field => { 
            "post_id" => "%{[data][postId]}"
            "author_id" => "%{[data][authorId]}"
            "post_title" => "%{[data][title]}"
          }
          add_tag => ["post_created"]
        }
      }
    }
  }

  # Process Comments Service logs
  if [service_name] == "comments-service" {
    if [message] =~ /^{.*}$/ {
      json {
        source => "message"
      }
      
      # Extract comment events
      if [action] == "comment_created" {
        mutate {
          add_field => { 
            "comment_id" => "%{[data][commentId]}"
            "post_id" => "%{[data][postId]}"
            "author_id" => "%{[data][authorId]}"
          }
          add_tag => ["comment_created"]
        }
      }
      
      # Extract moderation events
      if [action] == "comment_moderated" {
        mutate {
          add_field => { 
            "comment_id" => "%{[data][commentId]}"
            "moderation_result" => "%{[data][result]}"
            "moderator_id" => "%{[data][moderatorId]}"
          }
          add_tag => ["comment_moderated"]
        }
      }
    }
  }

  # Process Nginx access logs
  if "nginx" in [tags] {
    grok {
      match => { 
        "message" => "%{COMBINEDAPACHELOG}"
      }
    }
    
    date {
      match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
    }
    
    mutate {
      convert => { "response" => "integer" }
      convert => { "bytes" => "integer" }
    }
    
    # Categorize HTTP status codes
    if [response] {
      if [response] >= 200 and [response] < 300 {
        mutate { add_tag => ["success"] }
      } else if [response] >= 300 and [response] < 400 {
        mutate { add_tag => ["redirect"] }
      } else if [response] >= 400 and [response] < 500 {
        mutate { add_tag => ["client_error"] }
      } else if [response] >= 500 {
        mutate { add_tag => ["server_error"] }
      }
    }
  }

  # Process Docker logs
  if "docker" in [tags] {
    # Extract container information
    grok {
      match => { 
        "path" => "/var/lib/docker/containers/%{DATA:container_id}/%{GREEDYDATA}"
      }
    }
    
    # Parse Docker log format
    if [log] {
      mutate {
        rename => { "log" => "message" }
      }
    }
  }

  # Security event detection
  if [remote_ip] {
    # Detect suspicious IPs
    if [remote_ip] in ["127.0.0.1", "::1"] {
      mutate { add_tag => ["localhost"] }
    } else {
      # Add geolocation
      geoip {
        source => "remote_ip"
        target => "geoip"
        add_tag => ["geoip"]
      }
    }
  }

  # Error detection
  if [log_level] in ["ERROR", "error", "Error"] or [http_status] >= 500 {
    mutate { add_tag => ["error"] }
  }

  # Warning detection
  if [log_level] in ["WARN", "warn", "Warning"] or [http_status] >= 400 {
    mutate { add_tag => ["warning"] }
  }

  # Performance monitoring
  if [response_time] {
    mutate {
      convert => { "response_time" => "float" }
    }
    
    if [response_time] > 1000 {
      mutate { add_tag => ["slow_response"] }
    }
  }

  # Clean up fields
  mutate {
    remove_field => [ "beat", "input", "prospector", "offset" ]
  }
}

output {
  # Send to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "microservices-logs-%{+YYYY.MM.dd}"
    
    # Use service-specific indices for better performance
    if [service_name] {
      index => "%{service_name}-logs-%{+YYYY.MM.dd}"
    }
    
    # Template for index mapping
    template_name => "microservices"
    template => "/usr/share/logstash/templates/microservices.json"
    template_overwrite => true
  }

  # Send errors to a separate index
  if "error" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "microservices-errors-%{+YYYY.MM.dd}"
    }
  }

  # Send security events to security index
  if "authentication" in [tags] or "registration" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "microservices-security-%{+YYYY.MM.dd}"
    }
  }

  # Debug output (disable in production)
  if [fields][debug] == "true" {
    stdout {
      codec => rubydebug
    }
  }

  # Send critical errors to alerting system
  if [log_level] == "FATAL" or ([http_status] >= 500 and "server_error" in [tags]) {
    http {
      url => "http://alertmanager:9093/api/v1/alerts"
      http_method => "post"
      content_type => "application/json"
      format => "json"
      mapping => {
        "alerts" => [{
          "labels" => {
            "alertname" => "LogstashCriticalError"
            "service" => "%{service_name}"
            "severity" => "critical"
          }
          "annotations" => {
            "summary" => "Critical error in %{service_name}"
            "description" => "%{message}"
          }
        }]
      }
    }
  }
}